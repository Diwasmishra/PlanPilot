# ğŸ§  Smart Todo App (Next.js + Django + Supabase + LLaMA 7B)

An intelligent Plan Pilot todo app that combines a modern frontend, a powerful Django backend, local LLM-based AI, and a scalable cloud database. Built to demonstrate full-stack integration, backend API development, and local AI usage â€” all in one project.


## ğŸ”§ Tech Stack

| Layer      | Tech Used                                 |
|------------|-------------------------------------------|
| Frontend   | Next.js, Tailwind CSS                     |
| Backend    | Django REST Framework                     |
| Database   | Supabase (PostgreSQL + Realtime)          |
| AI Layer   | LM Studio with LLaMA 7B Chat model        |
| Dev Tools  | Git, .env, REST APIs                      |


## âœ¨ Features

- âœ… Add, edit, delete, and complete tasks
- ğŸ§  AI-generated suggestions using LLaMA 7B (via LM Studio)
- ğŸ§© Supabase PostgreSQL used as database (accessed via Django ORM)
- ğŸ”„ Backend APIs built using Django REST Framework
- ğŸ¨ Fully responsive UI with Tailwind CSS
- ğŸ” Environment secrets kept safe via `.env`

---

## ğŸ—‚ï¸ Folder Structure
PlanPilot/
â”œâ”€â”€ frontend/ # Next.js frontend (UI)
â”‚ â”œâ”€â”€ app/ # Pages and components
â”‚ â””â”€â”€ utils/ai.js # LLM integration with LM Studio
â”œâ”€â”€ backend/ # Django project
â”‚ â”œâ”€â”€ smart_backend/ # Django settings and URLs
â”‚ â”œâ”€â”€ todo/ # App logic, models, views, serializers
â”‚ â””â”€â”€ .env # Supabase credentials (ignored in git)
â””â”€â”€ README.md


---

## ğŸ§  How AI Integration Works

- LM Studio runs locally at `http://localhost:1234`
- Frontend sends user task to this local server
- LLaMA 7B model (chat version) responds with suggestions, rewrites, etc.

> ğŸ’¡ LM Studio eliminates the need for any external OpenAI API key or charges.

---

## ğŸ§ª Setup Guide

### 1. Clone the Repo

```bash
git clone https://github.com/Diwasmishra/<repo-name>.git
cd PlanPilot
```

### 2. Backend (Django + Supabase)
ğŸ“¦ Backend Setup
```bash
cd backend
python -m venv venv
source venv/Scripts/activate  # or source venv/bin/activate (Linux/Mac)
```
### 3. Install Requirements
```bash
pip install -r requirements.txt
```
### 3. ğŸ” Configure Supabase
Go to https://supabase.com

Create a project and get:

SUPABASE_URL

SUPABASE_KEY

In .env file:
```bash
SUPABASE_URL=https://<your>.supabase.co
SUPABASE_KEY=your-supabase-key
```
### 3. Migrate & Run the Backend
```bash
python manage.py migrate
python manage.py runserver
```

### 4. Frontend (Next.js + Tailwind)
```bash
cd ../frontend
npm install
npm run dev
```

App runs at: http://localhost:3000

### 5. Run LM Studio
Download from https://lmstudio.ai

Load a chat-compatible GGUF model (like LLaMA 7B Chat)

Set LM Studio to listen at http://localhost:1234

Start the model â€” keep this running

  
### ğŸ§¹ Best Practices Followed  

1] .env never pushed 

2]AI model is self-hosted (no OpenAI key leakage)

3] Clear folder structure (frontend/backend)

4] Secrets managed securely

5] REST API properly modularized using Django

### ğŸ”® Future Roadmap  

ğŸªª Supabase Auth (email sign-in)

ğŸ”” Email reminders

ğŸ§  Prioritize tasks by urgency/effort

ğŸ“± PWA support

ğŸ“¦ Dockerize both frontend and backend

### ğŸ‘¨â€ğŸ’» About Me
Hi, I'm Diwas Mishra â€” a full-stack developer passionate about blending AI with robust backend systems.

ğŸŒ https://www.linkedin.com/in/diwas-mishra-b2109a2a9

ğŸ“§ mishradiwasbrijesh@gmail.com
